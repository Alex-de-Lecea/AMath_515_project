{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyl_data = np.load('SamsStuff/data_numpy.npy')\n",
    "\n",
    "xy_coords = np.load('SamsStuff/xy_coords.npy').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Note the shape of our cylinder data:\n",
    "2000 timesteps, \n",
    "3 flow descriptors (x-velocity, y-velocity, vorticity), \n",
    "8744 grid points (interpolated elements onto FEM triangle centers)\n",
    "\n",
    "xy_coords gives array where row 1 is x-coords & row 2 is y-coords\n",
    "'''\n",
    "print(cyl_data.shape)\n",
    "print(xy_coords.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Little Visualization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cyl(coords, field, ax, levels=18):\n",
    "    numOfLevels=levels\n",
    "    vort_levels = np.append(np.append(np.array([-40]),np.linspace(-2,2,numOfLevels)),40)\n",
    "\n",
    "    ax.tricontourf(coords[0],coords[1], field, levels=vort_levels, vmin = -2,vmax=2, cmap='RdBu')\n",
    "    circle = plt.Circle((0, 0), 0.5, color='grey', clip_on=False)\n",
    "    ax.add_patch(circle)\n",
    "    ax.set_xlim(-1.5,12)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_cyl(xy_coords,cyl_data[-1,2,:],ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can use scatter plots but these kinda suck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xy_coords[0],xy_coords[1], s = 5, c = cyl_data[-1,2,:], vmin = -2,vmax=2, cmap='RdBu')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xlim(-2.5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a custom Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data shape and storage (list) to make torch happy\n",
    "U_list = []\n",
    "V_list = []\n",
    "vort_list = []\n",
    "\n",
    "for i in range(0,cyl_data.shape[0]):\n",
    "    U_list.append(np.reshape(cyl_data[i,0,:], (1,8744)))\n",
    "    V_list.append(np.reshape(cyl_data[i,1,:], (1,8744)))\n",
    "    vort_list.append(np.reshape(cyl_data[i,2,:], (1,8744)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dimension must be compatible with input layer (8744,128)\n",
    "print((U_list[2]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        item_as_np = self.data[index]\n",
    "        item_as_ten = torch.from_numpy(item_as_np).float()\n",
    "\n",
    "        return item_as_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 2000 total steps into test & train\n",
    "train_cylData = CustomDataset(vort_list[:1500])\n",
    "test_cylData = CustomDataset(vort_list[1500:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start implementing Dima's stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can prob tune the batch_size\n",
    "batch_size = 128\n",
    "cyl_DL_train = torch.utils.data.DataLoader(train_cylData, shuffle=True, batch_size=batch_size)\n",
    "cyl_DL_test = torch.utils.data.DataLoader(test_cylData, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "im_size = vort_list[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Reproducibility  \n",
    "torch.manual_seed(0);\n",
    "\n",
    "# Cylinder Data\n",
    "batch_size = 32\n",
    "cyl_DL_train = torch.utils.data.DataLoader(train_cylData, shuffle=True, batch_size=batch_size)\n",
    "cyl_DL_test = torch.utils.data.DataLoader(test_cylData, shuffle=True, batch_size=batch_size)\n",
    "im_size = vort_list[0].size\n",
    "\n",
    "sample = next(iter(cyl_DL_train))  #grab the next batch from the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Networks ###\n",
    "\n",
    "#Autoencoder params\n",
    "NN_width = 128 #size of hidden layers\n",
    "n_hidden = 5  #number of hidden layers on either size of latent space\n",
    "n_latent = 8 #size of latent space \n",
    "\n",
    "# Encoder as a fully connected network\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        #create input layer\n",
    "        Taper1 =  4096\n",
    "        Taper2 = 1024\n",
    "        self.l1 = nn.Linear(im_size, Taper1)\n",
    "        self.a1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        #create hidden layers\n",
    "        layers = []\n",
    "        # Implement a Taper Down\n",
    "        # Taper\n",
    "        layers.append(('hidden{}'.format(1),nn.Linear(Taper1, Taper2)))\n",
    "        layers.append(('ReLU{}'.format(1), nn.LeakyReLU(0.2, inplace=True)))\n",
    "\n",
    "        # Taper into NN_width\n",
    "        layers.append(('hidden{}'.format(2),nn.Linear(Taper2, NN_width)))\n",
    "        layers.append(('ReLU{}'.format(2), nn.LeakyReLU(0.2, inplace=True)))\n",
    "\n",
    "        for i in range(2,n_hidden):\n",
    "            layers.append(('hidden{}'.format(i+1),nn.Linear(NN_width, NN_width)))\n",
    "            #layers.append(('batch norm{}'.format(i+1),nn.BatchNorm1d(NN_width)))\n",
    "            layers.append(('ReLU{}'.format(i+1), nn.LeakyReLU(0.2, inplace=True)))\n",
    "        self.hidden = nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "        #output layer\n",
    "        self.out = nn.Linear(NN_width,n_latent)\n",
    "\n",
    "    #forward pass\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0],-1) #flatten the images into a vector\n",
    "        x = self.l1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.hidden(x)\n",
    "        return self.out(x)\n",
    "\n",
    "# Decoder as a fully connected network\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        #create input layer\n",
    "        self.l1 = nn.Linear(n_latent, NN_width)\n",
    "        self.a1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        #create hidden layers\n",
    "        layers = []\n",
    "        for i in range(n_hidden - 2):\n",
    "            layers.append(('hidden{}'.format(i+1),nn.Linear(NN_width, NN_width)))\n",
    "            #layers.append(('batch norm{}'.format(i+1),nn.BatchNorm1d(NN_width)))\n",
    "            layers.append(('ReLU{}'.format(i+1), nn.LeakyReLU(0.2, inplace=True)))\n",
    "\n",
    "        # Taper out too\n",
    "        Taper1 =  4096\n",
    "        Taper2 = 1024\n",
    "\n",
    "        layers.append(('hidden{}'.format(4),nn.Linear(NN_width, Taper2)))\n",
    "        #layers.append(('batch norm{}'.format(i+1),nn.BatchNorm1d(NN_width)))\n",
    "        layers.append(('ReLU{}'.format(4), nn.LeakyReLU(0.2, inplace=True)))\n",
    "\n",
    "        layers.append(('hidden{}'.format(5),nn.Linear(Taper2, Taper1)))\n",
    "        #layers.append(('batch norm{}'.format(i+1),nn.BatchNorm1d(NN_width)))\n",
    "        layers.append(('ReLU{}'.format(5), nn.LeakyReLU(0.2, inplace=True)))\n",
    "\n",
    "        self.hidden = nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "        #output layer\n",
    "        self.out = nn.Linear(Taper1,im_size)\n",
    "\n",
    "    #forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.hidden(x)\n",
    "        x = self.out(x)\n",
    "        return x.view(x.size()[0],im_size) #reshape to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        x = self.decoder(latent)\n",
    "        return x, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AutoEncoder().to(device)\n",
    "reconst, latent = net(sample[0].to(device))\n",
    "print('Reconstructed shape:', reconst.shape)\n",
    "print('Latent shape:', latent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizers import ProxGD\n",
    "from optimizers import GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters\n",
    "epochs = 5          #one epoch is one iteration through the entire training cylce\n",
    "iters_cycle = 200    #frequency of which to log results\n",
    "error = torch.nn.L1Loss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Autoencoder ###\n",
    "LR = 0.001\n",
    "\n",
    "#initialize error function and optimizer\n",
    "opt = torch.optim.Adam(net.parameters(), betas = (0.5, 0.999), lr = LR)\n",
    "scheduler1 = torch.optim.lr_scheduler.ExponentialLR(opt, gamma = 0.9)\n",
    "\n",
    "#save losses\n",
    "losses = []\n",
    "\n",
    "#train\n",
    "iters = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #iterate through dataloader\n",
    "    for batch in cyl_DL_train:\n",
    "        #separate batch into labels and images\n",
    "        images = batch[0].to(device)\n",
    "        \n",
    "        #make predictions\n",
    "        reconst, latent = net(images)\n",
    "        \n",
    "        #calculate loss\n",
    "        loss = error(reconst, images)\n",
    "        \n",
    "        #backpropagate gradients with Adam algorithm, this is the magic of pytorch and autograd\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        #reset gradients\n",
    "        net.zero_grad()\n",
    "        \n",
    "        #save losses\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        #log progress\n",
    "        if iters%iters_cycle==0:    \n",
    "            print('Epoch: {}/{}     Iter: {}     Loss: {}'.format(epoch, epochs, iters, loss.item()))\n",
    "        iters +=1\n",
    "    #scheduler1.step()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create test dataset and load into dataloader\n",
    "\n",
    "#display sample with label and prediction\n",
    "sample_test = next(iter(cyl_DL_test))\n",
    "reconst, latent = net(sample[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_test.shape)\n",
    "print(reconst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleTestSnapshot = np.reshape((sample_test[0].numpy()),(im_size,))\n",
    "singelTestReconstructed = np.reshape((reconst.detach().numpy()),(im_size,))\n",
    "\n",
    "# I guess I don't need to do this??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_test[0].shape)\n",
    "print(reconst.detach().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image and reconstruction side by side \n",
    "# fig, ax = plt.subplots(2,1, figsize = (6,10))\n",
    "# ax[0].scatter(xy_coords[0],xy_coords[1], s=5, c = sample_test[0], vmin = -2, vmax = 2, cmap='RdBu')\n",
    "# ax[0].set_xlim(-2.5,10)\n",
    "\n",
    "# ax[1].scatter(xy_coords[0],xy_coords[1], s=5, c = reconst.detach(), vmin = -2, vmax = 2, cmap='RdBu')\n",
    "# ax[1].set_xlim(-2.5,10)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (14,5))\n",
    "ax[0] = plot_cyl(xy_coords, singleTestSnapshot, ax[0])\n",
    "ax[1] = plot_cyl(xy_coords, singelTestReconstructed, ax[1])\n",
    "ax[0].set_title('Original')\n",
    "ax[1].set_title('Reconstructed with n_latent = ' + str(n_latent))\n",
    "plt.show()\n",
    "\n",
    "print(\"Reconstruction Error: \", error(reconst, sample[0].to(device)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss curve \n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('L1 Loss')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs Improvement:\n",
    "- More Data\n",
    "- Custom Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "617bc08694e68bf3a5b4ac8480bfc58e01cb1e284982b49f0cde9eaaf8b7dc86"
  },
  "kernelspec": {
   "display_name": "Python 3.12.2 ('AutoEncoder')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
